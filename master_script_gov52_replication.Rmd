---
title: "Gov52 Replication Project"
author: "Lindsey Greenhill"
date: "4/16/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gtools)
library(apsrtable)
library(MASS)
library(labelled)
library(gtsummary)
library(gt)
library(stargazer)
library(sjPlot)
library(ggpubr)
library(gtable)
library(grid)
library(gridExtra)
library(tidyverse)
```

```{r data, include=FALSE}

# reading in the two data frames the data is the almost 1,000 presidential
# disasters declared from 1981 to 2004. Unit is number of disasters in each
# state per year. So for 24 years and 50 states there are a total of 1,200 observations

data <- read.csv("data/political_disaster_replication_t2.csv",
                 stringsAsFactors = FALSE)

data <- data  %>%
  mutate(ppinc.adj.log = log(ppinc.adj))
data1<-read.csv("data/political_disaster_replication_t3.csv")

# giving data attribute labels
# classifying states as either high or low competition based off of median

data <- data %>%
  mutate(comp_level = if_else(comp > quantile(data$comp, .75, names = FALSE), "highly_competitive",
                              if_else(comp < quantile(data$comp, .25, names = FALSE), "not competitive", "medium")))

```



```{r tbl_1, include=FALSE}

# table 1 is summary statistics of presidential disaster declarations, actual
# disasters, electoral votes, competitiveness,  per  capita personal income
# (logged),insurance dollars (logged), congressional delegation sameparty as
# president, and governor same party as  the president


# creating initial  summary table to base for loop off of

sum_tab <- tibble(variable = "Presidential Disaster Declaration", Mean = mean(data$fema.dis),
                  Std_Dev = sd(data$fema.dis),
                  Min = min(data$fema.dis),
                  Max = max(data$fema.dis))

# just selecting variables I'm creating summaries of

data_sum <- data %>%
  select(fema.dis, priv.dis, ev, comp, ppinc.adj.log, INSURADJ.L, cong.pres, pres.party)

# creating a vector of labels for the summary table

labs <- c("Presidential Disaster Declarations", "Actual Disasters", "Electoral Votes",
          "Competitiveness", 
          "Per Capita Personal Income (logged)", 
          "InsuranceDollars (logged)", 
          "Congressional Delegation Same party as the President", 
          "Governor Same Party as the President")

# using a for loop to do the rest of the summary table

for(i in 2:8){
  mean <- mean(data_sum[,i])
  sd <- sd(data_sum[,i])
  min <- min(data_sum[,i])
  max <- max(data_sum[,i])
  vec <- tibble(variable = labs[i], Mean = mean,
                  Std_Dev = sd,
                  Min = min,
                  Max = max)
  sum_tab <- rbind(sum_tab, vec)
}

# turning summary table into gt object

tbl_1 <- sum_tab %>%
  gt() %>%
  fmt_number(columns = 2:5,
             decimals = 1)
```



```{r tbl_2, include=FALSE, results = "asis"}

# Table 2 Model of Presidential Disaster Declarations, Pooled Model (Column 1)
# and Split Sample Model (Columns 2 and 3) (p. 1147)

# Col 1 (full)

reg <- glm(fema.dis ~ priv.dis + INSURADJ.L + log(ppinc.adj) + ev + comp + reagan1 + reagan2 + bush + clinton1 + wbush + p2 + p3 + p4 + cong.pres + pres.party + as.factor(state),
         family = poisson,
         data=data)

# Col 2 (pre-Stafford). Replication code. 

reg1 <- glm(fema.dis ~ priv.dis + INSURADJ.L + log(ppinc.adj) + ev + comp + reagan1 + p2 + p3 + p4 + cong.pres + pres.party + as.factor(state),
            family = poisson, 
            data=data[data$year < 1989,])

# Col 3 (post-stafford)

reg2 <- glm(fema.dis ~ priv.dis + INSURADJ.L + log(ppinc.adj) + ev + comp + bush + clinton1 + wbush + p2 + p3 + p4 + cong.pres + pres.party + as.factor(state),
            family = poisson, 
            data=data[data$year>1988,])

# stargazer table

tbl_2 <- stargazer(reg, reg1, reg2,
          title = "Model of Presidential Disaster Declarations",
          type = "latex",
          omit = "state",
          order = c("comp", "priv.dis", "INSURADJ.L",
                    "ppinc.adj",
                    "ev", "p2", "p3", "p4",
                    "cong.pres", "pres.party",
                    "reagan1", "reagan2",
                    "bush", "clinton1", "wbush"),
          covariate.labels = c("Competitiveness", "Actual Disasters",
                               "Insurance cost (logged)", "Per capita income", "Electoral Votes", "year 2 of admin",
                               "year 3 of admin", "year 4 of admin", "Congressional partisanship", "President / Governor same party",
                               "Reagan (term 1)", "Reagan (term 2)", "GHW Bush",
                               "W Bush", "Clinton (term 1)", "Intercept"),
          digits = 2,
          # column.labels = c("full", "pre-Stafford", "post-Stafford"),
          keep.stat = c("n", "aic", "ll"))


```


```{r fig_1, message=FALSE, include=FALSE}

# creating data for post stafford. Maybe I should put this at the top?

data_post <- data %>%
  filter(year > 1988) %>%
  mutate(phat = predict(reg2, type = "response"))


# this isn't quite right/the same but I don't know why

ggplot(data_post, aes(x = comp, y = fema.dis)) +
  geom_smooth(method = "glm",
              method.args = list(family = "poisson")) +
  theme_classic()

fig_1 <- plot_model(reg2, type = "eff",
           terms = "comp",
           ci.lvl = NA,
           axis.lim = list(c(25,50), c(0,1.5))) +
  theme_classic() +
  labs(title = "Figure 1: Effect of Competitiveness  on Number\n of  Disaster Declarattions, Post-Stafford Act Only",
       x = "Competitiveness",
       y = "Expected Number of Disaster Declarations")
```


```{r fig_2, include=FALSE, message=FALSE, warning=FALSE}

# already made predictions for post stafford act but now need to do it for pre

data_pre <- data %>%
  filter(year < 1989) %>%
  mutate(phat = predict(reg1, type = "response"))


# looking at the difference in means pre stafford

pre_summaries <- data_pre %>%
  group_by(comp_level) %>%
  summarise(avg_phat = mean(phat))

# looking at the difference in means post stafford. Much  more of a difference

post_summaries <- data_post %>%
  group_by(comp_level) %>%
  summarise(avg_phat = mean(phat))

# filtering to only low and high competition (defined as 25% and 75% of
# competitiveness)

# creating first part of graph for pre stafford era using predictions from reg1

fig_2_a <- data_pre %>%
  filter(comp_level != "medium") %>%
  ggplot(aes(x = phat, fill = comp_level))  +
  geom_histogram(aes(y = ..density..), 
                 alpha = .5, binwidth = .075, position = "identity") +
  geom_vline(xintercept = .32, col = "indianred") +
  geom_vline(xintercept = .37, col = "steelblue2") +
  scale_x_continuous(limits = c(0,3)) +
  scale_fill_manual(values = c("indianred", "steelblue2")) +
  labs(title = "Predicted Disasters by Competitiveness Pre-Stafford",
       x = "Predicted Values",
       y = "Density") +
  theme_classic()

# creating second part of the graph for post stafford era using predictions from reg2

fig_2_b <- data_post %>%
  filter(comp_level != "medium") %>%
  ggplot(aes(x = phat, fill = comp_level))  +
  geom_histogram(aes(y = ..density..), 
                 alpha = .5, binwidth = .075, position = "identity") +
  geom_vline(xintercept = 1.05, col = "indianred") +
  geom_vline(xintercept = .55, col = "steelblue2") +
  scale_x_continuous(limits = c(0,3)) +
  scale_fill_manual(values = c("indianred", "steelblue2")) +
  labs(title = "Predicted Disasters by Competitiveness Post-Stafford",
       x = "Predicted Values",
       y = "Density") +
  theme_classic()

# putting the pre and post graphs together

fig_2 <- ggarrange(fig_2_a, fig_2_b,
          ncol = 1)

```


```{r tbl_3, include=FALSE}

# Col 1. Taken from replication code

pvote1 <- lm(curr.pct ~  prev.pct + fema.dis  + log(ppinc.adj) + pinc.chg + cong.pres + pres.party  + comp + ev + incumb + as.factor(state), 
             data = data1)

# Col 2. Taken from replication code

pvote2 <- lm(curr.pct ~  prev.pct + sqrt(fema.dis)  + log(ppinc.adj) + pinc.chg + cong.pres + pres.party  + comp + ev + incumb + as.factor(state),
             data = data1)

# making stargazer table

tbl_3 <- stargazer(pvote1, pvote2,
          title = "Model of State-Wide Presidential Election Outcomes",
          #align = TRUE,
          type = "text",
          omit = "state",
          order = c("fema.dis", "prev.pct",
                    "ppinc.adj", "pinc.chg",
                    "cong.pres", "pres.party",
                    "comp", "ev", "incumb"),
          covariate.labels = c("Presidential Disaster Declarations",
                               "Presidential Disaster Declarations (sqrt)",
                               "Previous Vote Share",
                               "Personal Per Capita Income (logged)",
                               "Change in Per Capita Income",
                               "Congressional Partisanship",
                               "Governor's Partisanship",
                               "Competitiveness",
                               "Electoral Votes",
                               "Incumbent",
                               "Intercept"),
          digits = 2,
          column.labels = c("Model 1", "Model 2"),
          keep.stat = c("n", "rsq",  "adj.rsq"))
```

# Replication of Political Disaster: Unilateral Powers, Electoral Incentives,
# and Presidential Disaster Declarations ^[The
data and code for this report can obtained at
https://github.com/lindseygreenhill/Gov52_replication_project]

In the following report, I replicate Andrew Reeves's 2011 paper "Political
Disaster: Unilateral Powers, Electoral Incentives,and Presidential Disaster
Declarations." ^[Reeves, Andrew. "Political Disaster: Unilateral Powers,
Electoral Incentives, and Presidential Disaster Declarations." The Journal of
Politics 73, no. 4 (2011): 1142-151.] I first provide an overview of the
original paper, then explain my replication process, and finally propose an
extension to Reeves's work.

## Overview

Reeves's work explores the relationship between presidential disaster
declarations and electoral competitiveness. It seeks to find evidence that
presidents disproportionately declare disasters and reward aid to electorally
competitive states in an effort to gain votes for reelection. For context, a
President can declare a disaster without the approval of other branches of
government. Such a declaration makes states eligible for grants and other sorts
of aid. In his analysis, Reeves utilizes a data set of all presidential disaster
declarations in the United States from 1981 to 2004. The unit of analysis is the
amount of disaster declarations in a state per year. Reeves purposefully split
his analysis into two parts: years before and after the Stafford Disaster Relief
and Emergenccy Assistance Act of 1988. The Stafford Act expanded the powers of
the president to provide disaster relief. Ultimately, Reeves finds that after
1988, there is a positive relationship between electoral competitiveness and
number and disaster declarations. Additionally, Reeves finds evidence that there
is a positive relationship between disaster declarations and electoral support,
meaning that states who received more disaster declarations were more likely to
support the incumbent president in the next election. In this report, I replicate
all of Reeves's models and figures in the Replication section. My findings are
consistent with his findings. I also extend his paper by looking at model 
performance in key states from 1981 to 2004. I find mixed results in this 
extension.

## Replication

For the replication part of this report, I replicated the paper's one summary
table, two models, and two figures. I will describe the specifics of each part
of the replication below.

* Note on the data: I did not have to do any data cleaning for the replication,
as the replication data had no missing values and was already transformed into
its final state

### Table 1

The first table I replicated is summary table of key variables used in Reeves's
analysis. The variables are as follows:

* Presidential Disaster Declarations: how many disasters declared a state for
that year

* Actual Disasters: objective count of disasters according to the Property
Claims Service, a branch of the Insurance Services Office (a private company
contracted by insurance companies)

* Electoral Votes

* Competitiveness: measured by the average of the loser's vote margin in the 
last three elections

* Logged Per Capita Personal Income

* Logged Insurance Dollars: the inflation-adjusted dollar value of the actual
disasters recorded by the ISO.

* Congressional Delegation Same party as the President: whether or not a state
congressional delegation's partisanship is the same as the president's

* Governor Same Party as the President: whether or not the governor's
partisanship is the same as the president's

```{r echo=FALSE}
tbl_1
```

### Discussion

There is significant variation across many of the variables, especially within
actual disasters and presidential disaster declarations. 

### Model 1

The first model I replicated is a Poisson regression. Reeves actually creates
three different models: one with all of the data from 1981 - 2004, one with data
pre stafford act (1981 to 1988), and one with data post Stafford act (1988 - 2004).
I replicated all three models. They are shown in the table below. 

As a reminder, the unit of analysis in the data set is a state-year. For example,
Wyoming in 1981. 

The dependent variable is **number of disaster declarations** in each state-year.

The independent variables are as follows:

* Competitiveness, actual disasters, logged insurance dolalrs, per capita
income, electoral votes, congressional/presidential partisanship,
gubernatorial/presidential partisanship, an indicator variable for year of
administration, and control variables for each administration from 1981 - 2004
(Reagan 1, Reagan 2, GHW Bush, Clinton, W Bush)

```{r echo=FALSE, results="asis", message=FALSE, warning=FALSE}
stargazer(reg, reg1, reg2,
          title = "Model of Presidential Disaster Declarations",
          type = "latex",
          omit = "state",
          order = c("comp", "priv.dis", "INSURADJ.L",
                    "ppinc.adj",
                    "ev", "p2", "p3", "p4",
                    "cong.pres", "pres.party",
                    "reagan1", "reagan2",
                    "bush", "clinton1", "wbush"),
          covariate.labels = c("Competitiveness", "Actual Disasters",
                               "Insurance cost (logged)", "Per capita income", "Electoral Votes", "year 2 of admin",
                               "year 3 of admin", "year 4 of admin", "Congressional partisanship", "President / Governor same party",
                               "Reagan (term 1)", "Reagan (term 2)", "GHW Bush",
                               "W Bush", "Clinton (term 1)", "Intercept"),
          digits = 2,
          # column.labels = c("full", "pre-Stafford", "post-Stafford"),
          keep.stat = c("n", "aic", "ll"),
          header = FALSE,
          no.space = TRUE,
          column.sep.width = "3pt",
          font.size = "small",
          #object.names = TRUE,
          column.labels = c("full", "pre", "post"))
```

### Discussion and Interpretation of Key Coefficients

* Interestingly, competitiveness is not statistically significant in the pre
Stafford act model. However, in both the full and post Stafford model, the
effect of competitiveness is positive and statistically significant. This makes
sense, as presidents did not have the power to make as large of an impact pre
stafford act. Post stafford act, it makes sense that presidents tried to
leverage their new power in the hopes of gaining more electoral support.

* The effect of actual disasters is positive and statistically significant in
all three models. It makes sense, and is perhaps obvious, that as actual
disasters increase disaster declarations also increase.

* The effect of insurance dollars is positive in all models but only
statistically significant for the full model. This suggests that the size of a
disaster is not necessarily correlated with an increased likelihood in a
disaster declaration.

* The effect of year of administration changes from pre Stafford to post
Stafford. Pre Stafford act, the president (Reagan) declared the most disasters
on average in year 2 of the administration. Post Stafford act, the presidents on
average declared the most disasters in year 4 of administration. It makes sense
that presidents were more likely to declare disasters near the end of their
term, in election years, if they wanted to gain the most electoral support for
their actions. It is similar to the way a president might enact more fiscal
policy in year 4 in an effort to boost the economy before an election.

### Figure 1

In the figure below, I show the marginal effect of competitiveness on predicted
disaster declarations for the post Stafford era model. I used the sjPlot 
library for my analysis. 

```{r  echo=FALSE}
fig_1
```


### Discussion

As competitiveness increases, the model predicts that the expected number of 
disaster declarations also increases. Looking at the model above, the effect
is statistically significant. Substantively, this finding suggests that 
presidents are more likely to give disaster support to key battleground states.

### Figure 2

The following figure also shows the effect of competitiveness on expected
disaster declarations. To produce the figure, I calculated the predicted y
values for both the pre and post stafford models (using the predict function). I
then classified the predicted y values by competitiveness. I defined a
prediction as highly competitive if it came from a state in the top 25 percent
of competitiveness. I defined a prediction as no competitive if it came from a
state in the bottom 25 percent of competitiveness.

```{r echo=FALSE}
fig_2
```


### Discussion

This figures shows the different effects of competitiveness for the pre and post
Stafford models. In the pre stafford model, the predicted y values for highly
competitive and not competitive states are not systematically different. The
average prediction values (shown by the vertical lines) for the two categories
are very similar. Contrastingly, the predicted values for the post Stafford 
model vary significantly based on competitiveness. The average predicted
value for highly competitive states is much higher than the average
predicted value for not competitive states. 

### Model 2

This Least Squares Regression looks at the effect of presidential disaster
declarations on election outcomes. Model 1 predicts election outcomes using
number of disaster declarations and Model 2 predicts election outcomes using the
square root transformation of the number of disaster declarations.

The dependent variable in this model is **presidential vote share**

The indepenent variables are as follows:

* number of presidential disaster declarations (sqrt of this in Model 2), party
vote share in last election, logged per capita income, change in per capita
income, whether or not the congressional delegation is the same party as the
president, whether or not the governor is the same party as the president,
competitiveness, electoral votes, whether or not the president is an incumbent,
and an indicator variable for each state.

```{r echo=FALSE, results = "asis"}
stargazer(pvote1, pvote2,
          title = "Model of State-Wide Presidential Election Outcomes",
          #align = TRUE,
          type = "latex",
          omit = "state",
          order = c("fema.dis", "prev.pct",
                    "ppinc.adj", "pinc.chg",
                    "cong.pres", "pres.party",
                    "comp", "ev", "incumb"),
          covariate.labels = c("Presidential Disaster Declarations",
                               "Presidential Disaster Declarations (sqrt)",
                               "Previous Vote Share",
                               "Personal Per Capita Income (logged)",
                               "Change in Per Capita Income",
                               "Congressional Partisanship",
                               "Governor's Partisanship",
                               "Competitiveness",
                               "Electoral Votes",
                               "Incumbent",
                               "Intercept"),
          digits = 2,
          column.labels = c("Model 1", "Model 2"),
          keep.stat = c("n", "rsq",  "adj.rsq"),
          header = FALSE,
          no.space = TRUE,
          column.sep.width = "3pt",
          font.size = "small")
```


### Discussion and Interpretation of Key Coefficients

* There is a statistically significant and positive relationship between
disaster declarations and vote share. Model 1 predicts that for every additional
disaster declaration, the presidential vote share increases by 1.29 points on
average, holding all else constant. Model 2 predicts that the first disaster
declaration results in an additional 2.17 point addition to the presidential
vote share on average, holding all else constant. Because Model 2 includes the
square root of disaster declarations, the second disaster declaration  will have
a smaller marginal effect of vote share, and  the third  declaration will have a
smaller effect than the second, and so on. These findings suggest that
presidential disaster declarations are effective in garnering support in
elections.

* The rest of the variables are meant for control and are not surprising.
Previous vote share, per capita income, change in per capita income,
congressional partisanship, and competitiveness are statistically
significant.


## Extension: predictions

In this section, I will look at how well Model 1 performed in certain states.
I chose to look at the states with the 5 largest variations in competitiveness
across 1981 to 2004. Those states ended up being Arizona, Georgia, Massachusetts,
Nevada, and New Hampshire. Looking at the visualization below, we can see
that MA grew considerably less competitive over time. NV, NH, GA, and AZ
all grew considerably more competitive over time. 

I looked at the predictions relative to 3 of the most significant coefficients
in the model, competitiveness, actual disasters, and fourth year in term.

All predictions before 1989 were made with the pre-Stafford era model. All 
predictions after 1988 were made with the post-Stafford model. 



```{r echo=FALSE, message=FALSE}

# arranging to find the states with the most variation in competitiveness. Those
# in top ten are Nevada, Georgia, New Hampshire, Arizona, MA, RI, FL, NY, WY, UT

most_comp_states <- data %>%
  group_by(state) %>%
  summarise(max = max(comp),
            min = min(comp),
            diff = max - min) %>%
  arrange(desc(diff)) %>%
  head(5) %>%
  pull(state)


# going to plot the competitiveness over time

variable_data <- data %>%
  filter(state %in% most_comp_states)

ext_1 <- variable_data %>%
  ggplot(aes(x = year, y = comp, col = state)) +
  geom_point() +
  geom_line() +
  labs(title = "Competitiveness over Time",
       subtitle = "States with most variation in competitiveness",
       x = "Year",
       y = "Competitiveness") +
  theme_classic()
ext_1
  
```

\newpage

```{r include = FALSE}

# now going to make a function that saves predictions for states

state_comp_pred <- function(s){
  
  # state df
  
  state_df <- data %>%
    filter(state == s)
  
  # data pre and post
  
  state_pre <- state_df %>%
    filter(year < 1989)
  state_post <- state_df %>%
    filter(year > 1988)
  
  # pre preds
  
  pre_pred <- predict(reg1, newdata = state_pre)
  pre_1 <- state_pre %>%
    cbind(pre_pred) %>%
    mutate(yhat = pre_pred) %>%
    select(-pre_pred)
  
  # post preds
  
  post_pred <- predict(reg2, newdata = state_post)
  post_1 <- state_post %>%
    cbind(post_pred) %>%
    mutate(yhat = post_pred) %>%
    select(-post_pred)
  
  # combining pred dfs
  
  state_comb <- rbind(pre_1, post_1)
  
  # plot of predictions vs actual
  
  pred_vs_real <- state_comb %>%
    ggplot(aes(x = year)) +
    geom_point(aes(y = yhat), col = "red") +
    geom_line(aes(y = yhat), col = "red") +
    geom_point(aes(y = fema.dis), col = "blue") +
    geom_line(aes(y = fema.dis), col = "blue") +
    labs(title = paste0(s, " Model Performance"),
         subtitle = "Predictions in red",
         x = "Year",
         y = "Disaster Declarations") +
    theme_classic()
  
  # actual disasters
  
  priv.dis <- state_comb %>%
    ggplot(aes(x = year, y = priv.dis)) +
    geom_point(col = "steelblue2") +
    labs(title = "Actual Disasters",
         subtitle = "Positive model coefficient (pre and post)",
         y = "Actual Disasters",
         x = "Year") +
    theme_classic()
  
  # comp
  
  comp <- state_comb %>%
    ggplot(aes(x = year, y = comp)) +
    geom_point(col = "steelblue2") +
    labs(title = "Competitiveness",
         subtitle = "Positive model coefficient post, negative pre",
         y = "Competitiveness",
         x = "Year") +
    theme_classic()
  
  # p4
  
  p4 <- state_comb %>%
    ggplot(aes(x = year, y = p4)) +
    geom_point(col = "steelblue2") +
    labs(title = "4th Year in Term",
         subtitle = "Positive model coefficient (pre and post)",
         y = "4th year",
         x = "Year") +
    theme_classic()
  
  results <- list(pred_vs_real, priv.dis,
                  comp, p4)
  
  return(results)
  
    
}

# key coefficients are priv.dis, comp, p4
```

```{r include = FALSE}

# function to arrange the plots I made above

ext_grid <- function(s){
  graphs <- state_comp_pred(s)
  grid <- ggarrange(graphs[[1]], graphs[[2]], 
             graphs[[3]], graphs[[4]])
  return(grid)

}

```

### Arizona

Looking at the graphs below, the model consistently under-predicted disaster
declarations in Arizona. However, we do see the model spike when the number of
actual disasters increased, which is consistent with the model. Interestingly,
we do not see the predictions substantively rise as competitiveness rise,
although the predictions do rise slightly with competitiveness. Similarly,
predicted disaster declarations do not seem to rise in the 4th term expect for
one instance in 1996. In fact, they decrease in most fourth term years.

```{r echo=FALSE}
ext_grid("Arizona")
```

\newpage

### Massachusetts

Similar to the Arizona situation, the model consistently under-predicted disaster
declarations in Massachusetts. We do not see the predictions lower considerably
with the competitiveness decreasing. As with the Arizona predictions, the 
model seems to react more to actual disasters. We do see more of a reaction
for the fourth year in term for Massachusetts. 

```{r echo=FALSE}
ext_grid("Massachusetts")
```

\newpage

### Georgia

The model massively underpredicts most years in Georgia, especially before the
Stafford Act. I'm not sure what is leading to these drastic numbers, but it is
worth looking further into. The model predictions do not seem to react in any
real way to an increase in competitiveness, actual disasters, or it being
the fourth year in term. 

```{r echo=FALSE}
ext_grid("Georgia")
```

\newpage

### New Hampshire

The model seems to do a better job for New Hampshire. The predictions start to 
increase steadily from about 1990, when both competittiveness and actual 
disasters tended to increase. The predictions also seem to react very mildly
to it being the fourth year in term. 

```{r echo=FALSE}
ext_grid("New Hampshire")
```

\newpage

### Nevada

As is the pattern in the previous states, the model consistently underpredicts
the number of disaster declarations in Nevada. However, We do see an steady increase
in the predictions as competitiveness increases. The model also seems to react
to the actual disasters, but not by as much I would expect it to. 

```{r echo=FALSE}
ext_grid("Nevada")
```

\newpage

### Summary

Looking the the model performance in these 5 key states gives us insight into
how the model reacts to changes in significant predictors. Evidently, the model
consistently underpredicts the number of disaster declarations in these states. 
Moreover, the model seems to react very slightly, if at all, to competitiveness,
actual disasters, and it being the fourth year in term. 

## Another Proposed Extension

Another possible extension to this model (which I will not look too far into in
this report) would be to extend the concepts of electoral incentives to Covid-19
relief. It is well documented in political science research that politicians
tend to give "incentives, or "political pork" to especially important regions in
the country and that this extra federal spending often results in an increase in
vote share. ^[Kriner, Douglas., and Andrew Reeves. "The Influence of Federal
Spending on Presidential Elections." The American Political Science Review 106,
no. 2 (2012): 348-66. Accessed May 6, 2021.
http://www.jstor.org/stable/41495082.] Thus, it is possible that differing
levels of COVID-19 relief could have affected the 2020 election. On the other
hand, there is a good possibility that this federal spending did not affect the
election, as more recent research has suggested that presidential approval has
become increasingly less motivated by economic activity. ^[Donovan, Kathleen,
Kellstedt, Paul M, Key, Ellen M, and Lebo, Matthew J. "Motivated Reasoning,
Public Opinion, and Presidential Approval." Political Behavior 42, no. 4 (2020):
1201-221] With this is mind, it is also possible that the effects and concepts
Reeves found in his paper are no longer applicable today. Further research
should dive into the durability of Reeves's model in the 2010's and 2020's.

## Conclusion 

In his original paper, Reeves finds that competitiveness is a statistically
significant predictor of presidential disaster declarations. He also finds 
that states who receive more disaster declarations typically more in 
favor of the President or his party. However, this effect was not present
until after the Stafford Act in 1988. In this report, I replicated all of 
the paper's models and figures as well as tested the model performance
on MA, AZ, GA, NV, and NH. These five states had the most variable competitiveness
over the 23 year period. The model consistently underperformed actual disaster
declarations and did not appear to be particulary senstive to any of the model's
primary predictors.

Further research could look at whether or not Covid-19 relief is correlated
with competitiveness or whether increased federal relief is associated with 
increased support for Donald Trump in the 2020 election. Other research could
also investigate whether or not political support is still linked to economy
status, as more recent work has suggested stronger partisan attachments have
lessened the importance of incumbent performance. 





